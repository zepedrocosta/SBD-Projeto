%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%                                                                           %
%                            Area for text                                  %
%                                                                           %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Introduction}
\label{sec:intro}

% Tirei da cena que vcs mandaram para o stor
This project aims to benchmark and compare the performance of different database systems using the TPC-C workload, a standard for evaluating OLTP (Online Transaction Processing) environments.

Automated scripts are used to run identical tests across multiple databases, each configured with similar settings to ensure a fair comparison.

Key metrics such as Transactions Per Minute (TPM) are measured under varying levels of concurrent users.

The results help identify the strengths and limitations of each database in handling transactional workloads.

In this test, the databases used were PostgreSQL, MySQL and MariaDB.

In total, we ran 54 tests:

\begin{itemize}
    \setlength\itemsep{0.1em}
    \item 4 tests scaling the number of virtual users (2 4 8 12) and warehouses (VU*5) on all PCs and databases (48 tests in total);
    \item 1 test with the number of virtual users set to the same as the number of threads in that PC, warehouses set to VU*5, allwarehouse = true on all databases on just one PC (3 test in total);
    \item 1 test with the number of virtual users set to the same as the number of threads in that PC, warehouses set to VU*5, with default config on all databases on just one PC (3 test in total).
\end{itemize}

\section{Overview of HammerDB}
\label{sec:hammerdb}

HammerDB is a free, open-source tool for benchmarking the performance of relational databases \cite{enwiki:1275860580}.

It supports popular databases like Oracle, SQL Server, PostgreSQL, MySQL, and more. HammerDB uses industry-standard workloads such as TPROC-C and TPROC-H to simulate real-world database activity.

It offers both a graphical interface and command-line options, making it suitable for developers, DBAs, and system administrators to test, compare, and tune database performance.

In some cases we used HammerDB in docker containers to run the tests, which allows for easy setup and isolation of the testing environment.

In another case, we used the Windows version of HammerDB to run the tests on a Windows machine.

\subsection{Overview of TPROC-C}
\label{sec:tproc-c}

TPROC-C is a benchmark designed to evaluate the performance of database management systems (DBMS) using a transactional workload. It simulates a typical online transaction processing (OLTP) environment, focusing on operations like inserts, updates, and deletes across multiple tables.

\subsection{TPROC-C vs TPROC-H}
\label{sec:tproc-c-vs-tproc-h}

TPROC-H is a benchmark designed for data warehousing and analytical workloads, while TPROC-C is focused on transactional processing. TPROC-H emphasizes complex queries and large data sets, whereas TPROC-C simulates real-time transactions with a focus on insert, update, and delete operations.

\section{Problem \& DBMS Summary}
\label{sec:problem}

\section{Benchmark Description}
\label{sec:benchmark}

\section{Methodology}
\label{sec:methodology}

\pagebreak

\subsection{Hardware and Software Setup}
\label{sec:hardware-software-setup}

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|c|c|}
        \hline
        \textbf{PC}      & \textbf{1}      & \textbf{2}       & \textbf{3}      & \textbf{4}    \\
        \hline
        \textbf{OS}      & Windows 11      & Windows 11       & Linux (Unraid)  & MacOS Sequoia \\
        \hline
        \textbf{CPU}     & Intel i7-13700H & AMD Ryzen 5 3600 & Intel i3-10100F & Apple M1      \\
        \hline
        \textbf{Cores}   & 14 (6P 8E)      & 6                & 4               & 8             \\
        \hline
        \textbf{Threads} & 20              & 12               & 8               & 8             \\
        \hline
        \textbf{RAM}     & 16GB            & 16GB             & 32GB            & 16GB          \\
        \hline
        \textbf{Disk}    & SSD M.2 NVMe    & SSD M.2 NVMe     & SSD M.2 NVMe    & SSD M.2 NVMe  \\
        \hline
        \textbf{Read}    & 3500 MB/s       & 2500 MB/s        & 3500 MB/s       & 3400 MB/s     \\
        \hline
        \textbf{Write}   & 2700 MB/s       & 2100 MB/s        & 3300 MB/s       & 2800 MB/s     \\
        \hline
    \end{tabular}
    \caption{Hardware used in the benchmarks}
    \label{t,ab:hardware-setup}
\end{table}

In PCs \textbf{1}, \textbf{3}, and \textbf{4}, we used HammerDB and all the databases in docker containers to run the tests, which allows for easy setup and isolation of the testing environment.

We used docker compose for this setup, which allowed us to easily run the same tests on different machines with the same configuration.

In PC \textbf{2}, we used everything installed on the host machine.

\subsection{Database Setup}
\label{sec:database-setup}

\section{Results}
\label{sec:results}

\section{Discussion}
\label{sec:discussion}

\section{Conclusions}
\label{sec:conclusions}
